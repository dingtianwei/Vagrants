---
- name: "Create kubernetes directory"
  file:
    path: "{{ item }}"
    mode: 0755
    state: directory
  with_items:
    - "~/.kube"
    - "/etc/kubernetes/pki"
  tags: dir

- name: "Create kubernetes log directory"
  file:
    path: "/var/log/kubernetes"
    mode: 0755
    state: directory
  tags: dir


- name: "Install master"
  copy:
    src: "{{ downloads_dir }}/kubernetes-{{ kubernetes.version }}/{{ item.line }}"
    mode: 0750
    dest: "/usr/bin/{{ item.line }}"
  with_items:
    - {line: "kubectl"}
    - {line: "kube-apiserver"}
    - {line: "kube-controller-manager"}
    - {line: "kube-scheduler"}
  tags: install_master

- name: "Distribution master certs"
  copy:
    src: "{{ item.line }}"
    dest: "/etc/kubernetes/pki/"
    mode: 0644
  with_items:
    - {line: '{{ cert.dir }}/ca.key'}
    - {line: '{{ cert.dir }}/ca.pem'}
    - {line: '{{ cert.dir }}/sa.key'}
    - {line: '{{ cert.dir }}/sa.pub'}
    - {line: '{{ cert.dir }}/etcd-ca.pem'}
    - {line: '{{ cert.dir }}/{{ inventory_hostname }}/apiserver.key'}
    - {line: '{{ cert.dir }}/{{ inventory_hostname }}/apiserver.pem'}
    - {line: '{{ cert.dir }}/{{ inventory_hostname }}/apiserver-etcd-client.key'}
    - {line: '{{ cert.dir }}/{{ inventory_hostname }}/apiserver-etcd-client.pem'}
    - {line: '{{ cert.dir }}/{{ inventory_hostname }}/apiserver-kubelet-client.key'}
    - {line: '{{ cert.dir }}/{{ inventory_hostname }}/apiserver-kubelet-client.pem'}
    - {line: '{{ cert.dir }}/front-proxy-ca.key'}
    - {line: '{{ cert.dir }}/front-proxy-ca.pem'}
    - {line: '{{ cert.dir }}/{{ inventory_hostname }}/front-proxy-client.key'}
    - {line: '{{ cert.dir }}/{{ inventory_hostname }}/front-proxy-client.pem'}
    - {line: '{{ cert.dir }}/{{ inventory_hostname }}/controller-manager.key'}
    - {line: '{{ cert.dir }}/{{ inventory_hostname }}/controller-manager.pem'}
    - {line: '{{ cert.dir }}/{{ inventory_hostname }}/scheduler.key'}
    - {line: '{{ cert.dir }}/{{ inventory_hostname }}/scheduler.pem'}
    - {line: '{{ cert.dir }}/{{ inventory_hostname }}/admin.key'}
    - {line: '{{ cert.dir }}/{{ inventory_hostname }}/admin.pem'}
  tags:
    - dis_master_certs
    - dis_certs

- name: "Distribution kubectl kubeconfig"
  template:
    src: "kubeconfig/admin.kubeconfig.j2"
    mode: 0640
    dest: "~/.kube/config"
  tags:
    - dis_kubectl_kubeconfig
    - dis_master_kubeconfig

- name: "Distribution master kubeconfig"
  template:
    src: "kubeconfig/{{ item.src }}"
    mode: 0640
    dest: "{{ item.dest }}"
  with_items:
    - {src: "admin.kubeconfig.j2",dest: "~/.kube/config" }
    - {src: "controller-manager.kubeconfig.j2",dest: "/etc/kubernetes/controller-manager.kubeconfig" }
    - {src: "scheduler.kubeconfig.j2",dest: "/etc/kubernetes/scheduler.kubeconfig" }
  tags: dis_master_kubeconfig



# Distribute kube-apiserver
- name: "Distribution kube-apiserver config"
  template:
    src: "config/kube-apiserver.conf.j2"
    mode: 0640
    dest: "/etc/kubernetes/kube-apiserver.conf"
  register: distribute_kube_apiserver_config
  tags: dis_master_config

- name: "Distribution kube-apiserver audit-poilcy"
  template:
    src: "config/audit-policy.yaml.j2"
    mode: 0640
    dest: "/etc/kubernetes/audit-policy.yaml"
  register: distribute_kube_apiserver_audit
  tags: dis_master_config

- name: "Distribution kube-apiserver systemd unit"
  template:
    src: "systemd_unit/kube-apiserver.service.j2"
    owner: root
    group: root
    mode: 0644
    dest: "/lib/systemd/system/kube-apiserver.service"
  register: distribute_kube_apiserver_systemd_unit
  tags: dis_master_systemd


# Distribute kube-controller-manager
- name: "Distribution controller-managerr config"
  template:
    src: "config/kube-controller-manager.conf.j2"
    mode: 0640
    dest: "/etc/kubernetes/kube-controller-manager.conf"
  # register: distribute_kube_controller_manager_config 
  tags: dis_master_config

- name: "Distribution kube-controller-manager systemd unit"
  template:
    src: "systemd_unit/kube-controller-manager.service.j2"
    owner: root
    group: root
    mode: 0644
    dest: "/lib/systemd/system/kube-controller-manager.service"
  # register: distribute_kube_controller_manager_systemd_unit
  tags: dis_master_systemd


# Distribute kube-scheduler
- name: "Distribution kube-scheduler config"
  template:
    src: "config/kube-scheduler.conf.j2"
    mode: 0640
    dest: "/etc/kubernetes/kube-scheduler.conf"
  # register: distribute_kube_scheduler_config
  tags: dis_master_config

- name: "Distribution kube-scheduler systemd unit"
  template:
    src: "systemd_unit/kube-scheduler.service.j2"
    owner: root
    group: root
    mode: 0644
    dest: "/lib/systemd/system/kube-scheduler.service"
  # register: distribute_kube_scheduler_systemd_unit
  tags: dis_master_systemd


- name: "Restart kube-apiserver"
  systemd:
    name: kube-apiserver
    state: restarted
    daemon_reload: yes
    enabled: yes
  # when: distribute_kube_apiserver_config.changed or distribute_kube_apiserver_systemd_unit.changed  or distribute_kube_apiserver_audit.changed
  tags: restart_apiserver
  

- name: "Restart kube-controller-manager"
  systemd:
    name: kube-controller-manager
    state: restarted
    daemon_reload: yes
    enabled: yes
  # when: distribute_kube_controller_manager_config.changed or distribute_kube_controller_manager_systemd_unit.changed
  tags: restart_controller

- name: "Restart kube-scheduler"
  systemd:
    name: kube-scheduler
    state: restarted
    daemon_reload: yes
    enabled: yes
  # when: distribute_kube_scheduler_config.changed or distribute_kube_scheduler_systemd_unit.changed
  tags: restart_scheduler

- name: "Add kubectl completion"
  lineinfile:
    dest: "/etc/profile"
    line: "source <(kubectl completion bash)"
    state: present

- name: "Waiting kube-apiserver starting"
  wait_for:
    host: "{{ ansible_host }}"
    port: 6443
    delay: 5
    sleep: 2
  # when: distribute_kube_apiserver_config.changed or distribute_kube_apiserver_systemd_unit.changed 
  tags: healthcheck

- name: "Waiting kube-controller-manager starting"
  wait_for:
    host: "{{ ansible_host }}"
    port: 10257
    delay: 5
    sleep: 2
  # when: distribute_kube_controller_manager_config.changed or distribute_kube_controller_manager_systemd_unit.changed
  tags: healthcheck

- name: "Waiting kube-scheduler starting"
  wait_for:
    host: "{{ ansible_host }}"
    port: 10259
    delay: 5
    sleep: 2
  # when: distribute_kube_scheduler_config.changed or distribute_kube_scheduler_systemd_unit.changed
  tags: healthcheck

- name: "Kube-apiserver health check"
  uri:
    url: "https://{{ ansible_host }}:6443/healthz"
    return_content: yes
    validate_certs: no
    client_cert: "{{ cert.dir }}/{{ inventory_hostname }}/admin.pem"
    client_key: "{{ cert.dir }}/{{ inventory_hostname }}/admin.key"
  register: apiserver
  failed_when: "'ok' not in apiserver.content"
  connection: local
  tags: healthcheck

- name: "Kube-controller-manager health check"
  uri:
    url: "https://{{ ansible_host }}:10257/healthz"
    return_content: yes
    validate_certs: no
  register: controller
  failed_when: "'ok' not in controller.content"
  connection: local
  tags: healthcheck

- name: "Kube-scheduler health check"
  uri:
    url: "https://{{ ansible_host }}:10259/healthz"
    return_content: yes
    validate_certs: no
  register: scheduler
  failed_when: "'ok' not in scheduler.content"
  connection: local
  tags: healthcheck






- name: "Distribution bootstarp.secret.yaml"
  template:
    src: "bootstrap.secret.yaml.j2"
    dest: "/etc/kubernetes/bootstrap.secret.yaml"
  register: bootstrap_yaml
  tags: dis_master_kubeconfig
  changed_when: bootstrap_yaml.failed



- name: "Kubelet apply bootstrap.secret.yaml"
  shell: kubectl apply -f  /etc/kubernetes/bootstrap.secret.yaml
  ignore_errors: yes
  delegate_to: "{{ groups['master'][0] }}"
  run_once: true
  register: bootstrap_token_ready
  changed_when: '" changed" in bootstrap_token_ready.stdout or " created" in bootstrap_token_ready.stdout' 
  tags: bootstrap

- name: "Delete bootstrap.secret.yaml"
  file:
    path: "/etc/kubernetes/bootstrap.secret.yaml"
    state: absent
  register: delete_bootstrap_yaml
  changed_when: delete_bootstrap_yaml.failed
  tags:
    - delete_token
    - bootstrap_token

- name: "register kubectl get cs"
  shell: kubectl get cs
  register: cluster_health
  changed_when: cluster_health.failed

- name: "View  kubectl get cs"
  debug: 
    msg: "{{ cluster_health.stdout.split('\n') }}" 
